{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load metamaps.py\n",
    "\"\"\"Provides methods for loading/saving metamaps\"\"\"\n",
    "import struct\n",
    "from enum import IntEnum\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import numbers\n",
    "\n",
    "METAMAP_FILE_VERSION = 0x100\n",
    "\n",
    "class TileType(IntEnum):\n",
    "    \"\"\"Tile types in a metamap\"\"\"\n",
    "    UNREACHABLE = 0\n",
    "    EMPTY = 1\n",
    "    WALL = 2\n",
    "    PUSHWALL = 3\n",
    "    DOOR = 4\n",
    "\n",
    "class EncodingDim(IntEnum):\n",
    "    \"\"\"Dimensions for the one-hot encoding of a metamap\"\"\"\n",
    "    PLAYABLE = 0\n",
    "    SOLID = 1\n",
    "    PASSAGE = 2\n",
    "\n",
    "TileTypeToEncodingDim = {\n",
    "    TileType.UNREACHABLE: EncodingDim.SOLID,\n",
    "    TileType.EMPTY: EncodingDim.PLAYABLE,\n",
    "    TileType.WALL: EncodingDim.SOLID,\n",
    "    TileType.PUSHWALL: EncodingDim.PASSAGE,\n",
    "    TileType.DOOR: EncodingDim.PASSAGE,\n",
    "    }\n",
    "\n",
    "class MetaMapsSequence(Sequence):\n",
    "    \"\"\"A sequence of real metamaps from a directory and randomly generated ones\"\"\"\n",
    "\n",
    "    def __init__(self, maps_dir, batch_size):\n",
    "        self.maps_dir = maps_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.map_files = os.listdir(maps_dir)\n",
    "        NUM_MAPS = len(self.map_files)\n",
    "        real_maps = [(index, True) for index in range(NUM_MAPS)]\n",
    "        fake_maps = [(index + NUM_MAPS, False) for index in range(NUM_MAPS)]\n",
    "        map_order = real_maps + fake_maps\n",
    "        np.random.shuffle(map_order)\n",
    "        self.map_order = map_order\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.map_order) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        map_batch = np.zeros((self.batch_size, 64, 64, len(EncodingDim)))\n",
    "        label_batch = np.zeros((self.batch_size))\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            (index, real_map) = self.map_order[idx * self.batch_size + i]\n",
    "            if real_map:\n",
    "                label_batch[i] = 1\n",
    "                map_batch[i:] = load_metamap(\n",
    "                    os.path.join(self.maps_dir, self.map_files[index]))\n",
    "            else:\n",
    "                map_batch[i:] = generate_random_map()\n",
    "\n",
    "        return map_batch, label_batch\n",
    "\n",
    "\n",
    "def generate_random_map():\n",
    "    \"\"\"Generate a random map\"\"\"\n",
    "    width = 64\n",
    "    height = 64\n",
    "    size = width * height\n",
    "\n",
    "    junk_map = np.zeros([size, len(EncodingDim)])\n",
    "\n",
    "    for i in range(size):\n",
    "        tile_type = random.randint(0, len(EncodingDim) - 1)\n",
    "        junk_map[i, tile_type] = 1\n",
    "\n",
    "    junk_map.shape = (width, height, len(EncodingDim))\n",
    "\n",
    "    return junk_map\n",
    "\n",
    "\n",
    "def load_smashed_metamap(filename):\n",
    "    \"\"\"Loads a condensed metamap file\"\"\"\n",
    "    with open(filename, \"rb\") as fin:\n",
    "        mega_meta_map = np.fromfile(fin, dtype=np.uint8)\n",
    "    return mega_meta_map\n",
    "\n",
    "\n",
    "def load_all_metamaps(dirname, number_cap=None):\n",
    "    \"\"\"Loads all the metamaps in the given directory, returning a giant numpy array\"\"\"\n",
    "    map_names = os.listdir(dirname)\n",
    "    if isinstance(number_cap, numbers.Integral) and number_cap > 0:\n",
    "        map_names = map_names[:number_cap]\n",
    "    all_maps = np.zeros((len(map_names), 64, 64, len(EncodingDim)))\n",
    "\n",
    "    for index, map_name in enumerate(map_names):\n",
    "        load_metamap_into(os.path.join(dirname, map_name), all_maps, index)\n",
    "\n",
    "    return all_maps\n",
    "\n",
    "\n",
    "def load_metamap_into(filename, all_maps, index):\n",
    "    \"\"\"Loads a metamap from a file into a numpy array of shape (width, height, 3)\"\"\"\n",
    "    with open(filename, \"rb\") as fin:\n",
    "        version = struct.unpack('Q', fin.read(8))[0]\n",
    "\n",
    "        if version != METAMAP_FILE_VERSION:\n",
    "            raise ValueError(\"Unsupported metamap version\")\n",
    "\n",
    "        width = struct.unpack('i', fin.read(4))[0]\n",
    "        height = struct.unpack('i', fin.read(4))[0]\n",
    "\n",
    "        raw_map = np.fromfile(fin, dtype=np.uint8)\n",
    "        raw_map.shape = (width, height)\n",
    "\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                tile_type = TileType(raw_map[y, x])\n",
    "                all_maps[index, y, x, TileTypeToEncodingDim[tile_type]] = 1\n",
    "\n",
    "\n",
    "def load_metamap(filename):\n",
    "    \"\"\"Loads a metamap from a file into a numpy array of shape (width, height, 3)\"\"\"\n",
    "    with open(filename, \"rb\") as fin:\n",
    "        version = struct.unpack('Q', fin.read(8))[0]\n",
    "\n",
    "        if version != METAMAP_FILE_VERSION:\n",
    "            raise ValueError(\"Unsupported metamap version\")\n",
    "\n",
    "        width = struct.unpack('i', fin.read(4))[0]\n",
    "        height = struct.unpack('i', fin.read(4))[0]\n",
    "        size = width * height\n",
    "\n",
    "        raw_map = np.fromfile(fin, dtype=np.uint8)\n",
    "        one_hot = np.zeros([size, len(EncodingDim)])\n",
    "\n",
    "        for i in range(size):\n",
    "            tile_type = TileType(raw_map[i])\n",
    "            one_hot[i, TileTypeToEncodingDim[tile_type]] = 1\n",
    "\n",
    "        one_hot.shape = (width, height, len(EncodingDim))\n",
    "\n",
    "        return one_hot\n",
    "\n",
    "\n",
    "def save_metamap(metamap, filename):\n",
    "    \"\"\"Saves a metamap to a file\"\"\"\n",
    "    with open(filename, \"wb\") as fout:\n",
    "        fout.write(struct.pack('Q', METAMAP_FILE_VERSION))\n",
    "\n",
    "        width = metamap.shape[0]\n",
    "        height = metamap.shape[1]\n",
    "\n",
    "        fout.write(struct.pack('i', width))\n",
    "        fout.write(struct.pack('i', height))\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                tile_type = TileType.WALL\n",
    "                if metamap[y, x, EncodingDim.PLAYABLE] == 1:\n",
    "                    tile_type = TileType.EMPTY\n",
    "                elif metamap[y, x, EncodingDim.SOLID] == 1:\n",
    "                    tile_type = TileType.WALL\n",
    "                elif metamap[y, x, EncodingDim.PASSAGE] == 1:\n",
    "                    tile_type = TileType.DOOR\n",
    "\n",
    "                fout.write(struct.pack('b', tile_type))\n",
    "    return\n",
    "\n",
    "def save_map_as_text(encoded_map, filename):\n",
    "    \"\"\"Saves a numpy array of size 64x64x3 representing an encoded Wolf map as a text file\"\"\"\n",
    "    with open(filename, \"w\") as fout:\n",
    "        for y in range(64):\n",
    "            for x in range(64):\n",
    "                if encoded_map[y, x, EncodingDim.PLAYABLE] == 1:\n",
    "                    tile = ' '\n",
    "                elif encoded_map[y, x, EncodingDim.SOLID] == 1:\n",
    "                    tile = '#'\n",
    "                elif encoded_map[y, x, EncodingDim.PASSAGE] == 1:\n",
    "                    tile = '+'\n",
    "\n",
    "                fout.write(tile)\n",
    "            fout.write('\\n')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega = load_smashed_metamap(\"MegaMetaMapCondensed\").astype('bool')\n",
    "print(f\"Mega shape: {mega.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 64\n",
    "HEIGHT = 64\n",
    "ALPHABET = len(EncodingDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega.shape = (int(mega.shape[0]/ALPHABET), ALPHABET)\n",
    "print(f\"Mega reshaped: {mega.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = int(mega.shape[0]/WIDTH)\n",
    "print(f\"Number of rows: {num_rows:,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_step = 4\n",
    "total_samples = int((mega.shape[0] - WIDTH - 1) / sampling_step)\n",
    "\n",
    "print(f\"Total samples: {total_samples:,d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.zeros((total_samples, WIDTH, ALPHABET), dtype=np.bool)\n",
    "next_tiles = np.zeros((total_samples, ALPHABET), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_byte_size = samples.size * samples.dtype.itemsize\n",
    "next_tiles_byte_size = next_tiles.size * next_tiles.dtype.itemsize\n",
    "print(f\"Samples size: {sizeof_fmt(samples_byte_size)}\")\n",
    "print(f\"Next Tiles size: {sizeof_fmt(next_tiles_byte_size)}\")\n",
    "print(f\"Total: {sizeof_fmt(samples_byte_size + next_tiles_byte_size)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_index in range(total_samples):\n",
    "    start_offset = sample_index * sampling_step\n",
    "    samples[sample_index] = mega[start_offset: start_offset + WIDTH]\n",
    "    next_tiles[sample_index] = mega[start_offset + WIDTH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(WIDTH, ALPHABET)))\n",
    "model.add(layers.Dense(ALPHABET, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "output_dir = \"tiledriver_ltsm\"\n",
    "shutil.rmtree(output_dir, ignore_errors=True)\n",
    "os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "\n",
    "print(f\"Started: {datetime.datetime.time(datetime.datetime.now())}\")\n",
    "\n",
    "EPOCHS = 60\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    model.fit(samples, next_tiles, batch_size=128, epochs=1)\n",
    "    start_row_index = random.randint(0, num_rows) * WIDTH\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        generated_map = np.zeros((HEIGHT*WIDTH,ALPHABET))\n",
    "        generated_map[0:WIDTH] = mega[start_row_index: start_row_index + WIDTH]      \n",
    "        for i in range((HEIGHT-1)*WIDTH):\n",
    "            sampled = generated_map[i:i+WIDTH]\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_tile = sample(preds, temperature)\n",
    "            generated_map[WIDTH + i, next_tile] = 1\n",
    "        generated_map.shape = (HEIGHT,WIDTH,ALPHABET)\n",
    "        save_map_as_text(generated_map, os.path.join(output_dir, f\"epoch_{epoch:02}_t{temperature}.txt\")\n",
    "\n",
    "print(f\"Done: {datetime.datetime.time(datetime.datetime.now())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
