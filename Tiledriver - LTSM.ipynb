{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %load metamaps.py\n",
    "\"\"\"Provides methods for loading/saving metamaps\"\"\"\n",
    "import struct\n",
    "from enum import IntEnum\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import numbers\n",
    "\n",
    "METAMAP_FILE_VERSION = 0x100\n",
    "\n",
    "class TileType(IntEnum):\n",
    "    \"\"\"Tile types in a metamap\"\"\"\n",
    "    UNREACHABLE = 0\n",
    "    EMPTY = 1\n",
    "    WALL = 2\n",
    "    PUSHWALL = 3\n",
    "    DOOR = 4\n",
    "\n",
    "class EncodingDim(IntEnum):\n",
    "    \"\"\"Dimensions for the one-hot encoding of a metamap\"\"\"\n",
    "    PLAYABLE = 0\n",
    "    SOLID = 1\n",
    "    PASSAGE = 2\n",
    "\n",
    "TileTypeToEncodingDim = {\n",
    "    TileType.UNREACHABLE: EncodingDim.SOLID,\n",
    "    TileType.EMPTY: EncodingDim.PLAYABLE,\n",
    "    TileType.WALL: EncodingDim.SOLID,\n",
    "    TileType.PUSHWALL: EncodingDim.PASSAGE,\n",
    "    TileType.DOOR: EncodingDim.PASSAGE,\n",
    "    }\n",
    "\n",
    "class MetaMapsSequence(Sequence):\n",
    "    \"\"\"A sequence of real metamaps from a directory and randomly generated ones\"\"\"\n",
    "\n",
    "    def __init__(self, maps_dir, batch_size):\n",
    "        self.maps_dir = maps_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.map_files = os.listdir(maps_dir)\n",
    "        NUM_MAPS = len(self.map_files)\n",
    "        real_maps = [(index, True) for index in range(NUM_MAPS)]\n",
    "        fake_maps = [(index + NUM_MAPS, False) for index in range(NUM_MAPS)]\n",
    "        map_order = real_maps + fake_maps\n",
    "        np.random.shuffle(map_order)\n",
    "        self.map_order = map_order\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.map_order) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        map_batch = np.zeros((self.batch_size, 64, 64, len(EncodingDim)))\n",
    "        label_batch = np.zeros((self.batch_size))\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            (index, real_map) = self.map_order[idx * self.batch_size + i]\n",
    "            if real_map:\n",
    "                label_batch[i] = 1\n",
    "                map_batch[i:] = load_metamap(\n",
    "                    os.path.join(self.maps_dir, self.map_files[index]))\n",
    "            else:\n",
    "                map_batch[i:] = generate_random_map()\n",
    "\n",
    "        return map_batch, label_batch\n",
    "\n",
    "\n",
    "def generate_random_map():\n",
    "    \"\"\"Generate a random map\"\"\"\n",
    "    width = 64\n",
    "    height = 64\n",
    "    size = width * height\n",
    "\n",
    "    junk_map = np.zeros([size, len(EncodingDim)])\n",
    "\n",
    "    for i in range(size):\n",
    "        tile_type = random.randint(0, len(EncodingDim) - 1)\n",
    "        junk_map[i, tile_type] = 1\n",
    "\n",
    "    junk_map.shape = (width, height, len(EncodingDim))\n",
    "\n",
    "    return junk_map\n",
    "\n",
    "\n",
    "def load_smashed_metamap(filename):\n",
    "    \"\"\"Loads a condensed metamap file\"\"\"\n",
    "    with open(filename, \"rb\") as fin:\n",
    "        mega_meta_map = np.fromfile(fin, dtype=np.uint8)\n",
    "    return mega_meta_map\n",
    "\n",
    "\n",
    "def load_all_metamaps(dirname, number_cap=None):\n",
    "    \"\"\"Loads all the metamaps in the given directory, returning a giant numpy array\"\"\"\n",
    "    map_names = os.listdir(dirname)\n",
    "    if isinstance(number_cap, numbers.Integral) and number_cap > 0:\n",
    "        map_names = map_names[:number_cap]\n",
    "    all_maps = np.zeros((len(map_names), 64, 64, len(EncodingDim)))\n",
    "\n",
    "    for index, map_name in enumerate(map_names):\n",
    "        load_metamap_into(os.path.join(dirname, map_name), all_maps, index)\n",
    "\n",
    "    return all_maps\n",
    "\n",
    "\n",
    "def load_metamap_into(filename, all_maps, index):\n",
    "    \"\"\"Loads a metamap from a file into a numpy array of shape (width, height, 3)\"\"\"\n",
    "    with open(filename, \"rb\") as fin:\n",
    "        version = struct.unpack('Q', fin.read(8))[0]\n",
    "\n",
    "        if version != METAMAP_FILE_VERSION:\n",
    "            raise ValueError(\"Unsupported metamap version\")\n",
    "\n",
    "        width = struct.unpack('i', fin.read(4))[0]\n",
    "        height = struct.unpack('i', fin.read(4))[0]\n",
    "\n",
    "        raw_map = np.fromfile(fin, dtype=np.uint8)\n",
    "        raw_map.shape = (width, height)\n",
    "\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                tile_type = TileType(raw_map[y, x])\n",
    "                all_maps[index, y, x, TileTypeToEncodingDim[tile_type]] = 1\n",
    "\n",
    "\n",
    "def load_metamap(filename):\n",
    "    \"\"\"Loads a metamap from a file into a numpy array of shape (width, height, 3)\"\"\"\n",
    "    with open(filename, \"rb\") as fin:\n",
    "        version = struct.unpack('Q', fin.read(8))[0]\n",
    "\n",
    "        if version != METAMAP_FILE_VERSION:\n",
    "            raise ValueError(\"Unsupported metamap version\")\n",
    "\n",
    "        width = struct.unpack('i', fin.read(4))[0]\n",
    "        height = struct.unpack('i', fin.read(4))[0]\n",
    "        size = width * height\n",
    "\n",
    "        raw_map = np.fromfile(fin, dtype=np.uint8)\n",
    "        one_hot = np.zeros([size, len(EncodingDim)])\n",
    "\n",
    "        for i in range(size):\n",
    "            tile_type = TileType(raw_map[i])\n",
    "            one_hot[i, TileTypeToEncodingDim[tile_type]] = 1\n",
    "\n",
    "        one_hot.shape = (width, height, len(EncodingDim))\n",
    "\n",
    "        return one_hot\n",
    "\n",
    "\n",
    "def save_metamap(metamap, filename):\n",
    "    \"\"\"Saves a metamap to a file\"\"\"\n",
    "    with open(filename, \"wb\") as fout:\n",
    "        fout.write(struct.pack('Q', METAMAP_FILE_VERSION))\n",
    "\n",
    "        width = metamap.shape[0]\n",
    "        height = metamap.shape[1]\n",
    "\n",
    "        fout.write(struct.pack('i', width))\n",
    "        fout.write(struct.pack('i', height))\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                tile_type = TileType.WALL\n",
    "                if metamap[y, x, EncodingDim.PLAYABLE] == 1:\n",
    "                    tile_type = TileType.EMPTY\n",
    "                elif metamap[y, x, EncodingDim.SOLID] == 1:\n",
    "                    tile_type = TileType.WALL\n",
    "                elif metamap[y, x, EncodingDim.PASSAGE] == 1:\n",
    "                    tile_type = TileType.DOOR\n",
    "\n",
    "                fout.write(struct.pack('b', tile_type))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reweight_distribution(original_distribution, temperature=0.5):\n",
    "    distribution = np.log(original_distribution) / temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    return distribution / np.sum(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mega shape: (420950016,)\n"
     ]
    }
   ],
   "source": [
    "mega = load_smashed_metamap(\"MegaMetaMap\").astype(\"bool\")\n",
    "print(f\"Mega shape: {mega.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 64\n",
    "HEIGHT = 64\n",
    "ALPHABET = len(EncodingDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mega reshaped: (140316672, 3)\n"
     ]
    }
   ],
   "source": [
    "mega.shape = (int(mega.shape[0]/ALPHABET), ALPHABET)\n",
    "print(f\"Mega reshaped: {mega.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2,192,448\n",
      "Number of maps: 34,257\n"
     ]
    }
   ],
   "source": [
    "num_rows = int(mega.shape[0]/WIDTH)\n",
    "num_maps = int(mega.shape[0]/WIDTH/HEIGHT)\n",
    "print(f\"Number of rows: {num_rows:,d}\")\n",
    "print(f\"Number of maps: {num_maps:,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in map: 1,343\n"
     ]
    }
   ],
   "source": [
    "sampling_step = 3\n",
    "samples_in_map = int((WIDTH * (HEIGHT - 1) - 1) / sampling_step)\n",
    "\n",
    "print(f\"Samples in map: {samples_in_map:,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 46,007,151\n"
     ]
    }
   ],
   "source": [
    "total_samples = samples_in_map * num_maps\n",
    "print(f\"Total samples: {total_samples:,d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.zeros((total_samples, WIDTH, ALPHABET), dtype=np.bool)\n",
    "next_tiles = np.zeros((total_samples, ALPHABET), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences size: 8.2GiB\n",
      "Next Tiles size: 131.6MiB\n",
      "Total: 8.4GiB\n"
     ]
    }
   ],
   "source": [
    "sentences_byte_size = sentences.size * sentences.dtype.itemsize\n",
    "next_tiles_byte_size = next_tiles.size * next_tiles.dtype.itemsize\n",
    "print(f\"Sentences size: {sizeof_fmt(sentences_byte_size)}\")\n",
    "print(f\"Next Tiles size: {sizeof_fmt(next_tiles_byte_size)}\")\n",
    "print(f\"Total: {sizeof_fmt(sentences_byte_size + next_tiles_byte_size)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for map_num in range(num_maps):\n",
    "    map_offset = map_num * WIDTH * HEIGHT \n",
    "    for sample_index in range(samples_in_map):\n",
    "        start_offset = map_offset + sample_index * sampling_step\n",
    "        sentence_index = map_num*samples_in_map + sample_index\n",
    "        sentences[sentence_index] = mega[start_offset: start_offset + WIDTH]\n",
    "        next_tiles[sentence_index] = mega[start_offset + WIDTH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(WIDTH, ALPHABET)))\n",
    "model.add(layers.Dense(ALPHABET, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This still needs work\n",
    "# Need some way to display a map (text? image?)\n",
    "# Force it sample stuff into a generated map of some sort\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "\n",
    "print(f\"Started: {datetime.datetime.time(datetime.datetime.now())}\")\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    model.fit(sentences, next_tiles, batch_size=128, epochs=1)\n",
    "    start_index = random.randint(0, num_rows) * WIDTH\n",
    "    generated_map = text[start_index: start_index + WIDTH]\n",
    "    print('--- Generating with seed: \"' + generated_map + '\"')\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        print()\n",
    "        sys.stdout.write(generated_map)\n",
    "\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "        print()\n",
    "\n",
    "print(f\"Done: {datetime.datetime.time(datetime.datetime.now())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
