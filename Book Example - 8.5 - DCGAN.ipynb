{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-account/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/jupyter-account/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "generator = keras.models.Model(generator_input, x)                   #3\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0008,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "                     loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-account/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10000:\n",
      "  discriminator loss: 0.6826667189598083\n",
      "  adversarial loss: 0.6764920949935913\n",
      "100/10000:\n",
      "  discriminator loss: 0.45859408378601074\n",
      "  adversarial loss: 1.808218002319336\n",
      "200/10000:\n",
      "  discriminator loss: 0.6916437745094299\n",
      "  adversarial loss: 0.7460620999336243\n",
      "300/10000:\n",
      "  discriminator loss: 0.6980230212211609\n",
      "  adversarial loss: 0.7770370244979858\n",
      "400/10000:\n",
      "  discriminator loss: 0.6944787502288818\n",
      "  adversarial loss: 0.733106255531311\n",
      "500/10000:\n",
      "  discriminator loss: 0.6892963647842407\n",
      "  adversarial loss: 0.7772891521453857\n",
      "600/10000:\n",
      "  discriminator loss: 0.7015835046768188\n",
      "  adversarial loss: 0.7289963960647583\n",
      "700/10000:\n",
      "  discriminator loss: 0.6864560842514038\n",
      "  adversarial loss: 0.7504480481147766\n",
      "800/10000:\n",
      "  discriminator loss: 0.687759280204773\n",
      "  adversarial loss: 0.7427811622619629\n",
      "900/10000:\n",
      "  discriminator loss: 0.6957899332046509\n",
      "  adversarial loss: 0.7666605114936829\n",
      "1000/10000:\n",
      "  discriminator loss: 0.7194489240646362\n",
      "  adversarial loss: 0.75782310962677\n",
      "1100/10000:\n",
      "  discriminator loss: 0.7017209529876709\n",
      "  adversarial loss: 0.7475947141647339\n",
      "1200/10000:\n",
      "  discriminator loss: 0.7140036225318909\n",
      "  adversarial loss: 0.8311213254928589\n",
      "1300/10000:\n",
      "  discriminator loss: 0.7042017579078674\n",
      "  adversarial loss: 0.7670242190361023\n",
      "1400/10000:\n",
      "  discriminator loss: 0.6921654939651489\n",
      "  adversarial loss: 0.7096601724624634\n",
      "1500/10000:\n",
      "  discriminator loss: 0.6968058347702026\n",
      "  adversarial loss: 0.7705381512641907\n",
      "1600/10000:\n",
      "  discriminator loss: 0.6899495124816895\n",
      "  adversarial loss: 0.7558814883232117\n",
      "1700/10000:\n",
      "  discriminator loss: 0.6876382231712341\n",
      "  adversarial loss: 0.7656354308128357\n",
      "1800/10000:\n",
      "  discriminator loss: 0.6887918710708618\n",
      "  adversarial loss: 0.7696688771247864\n",
      "1900/10000:\n",
      "  discriminator loss: 0.6903114318847656\n",
      "  adversarial loss: 0.8705212473869324\n",
      "2000/10000:\n",
      "  discriminator loss: 0.690913736820221\n",
      "  adversarial loss: 0.7703630328178406\n",
      "2100/10000:\n",
      "  discriminator loss: 0.6926487684249878\n",
      "  adversarial loss: 0.7566609382629395\n",
      "2200/10000:\n",
      "  discriminator loss: 0.6887826919555664\n",
      "  adversarial loss: 0.8654147982597351\n",
      "2300/10000:\n",
      "  discriminator loss: 0.69672691822052\n",
      "  adversarial loss: 0.720568060874939\n",
      "2400/10000:\n",
      "  discriminator loss: 0.7164274454116821\n",
      "  adversarial loss: 0.7148548364639282\n",
      "2500/10000:\n",
      "  discriminator loss: 0.7101828455924988\n",
      "  adversarial loss: 0.8242965936660767\n",
      "2600/10000:\n",
      "  discriminator loss: 0.7033095359802246\n",
      "  adversarial loss: 0.7366032600402832\n",
      "2700/10000:\n",
      "  discriminator loss: 0.7094513177871704\n",
      "  adversarial loss: 0.7389014959335327\n",
      "2800/10000:\n",
      "  discriminator loss: 0.7066398859024048\n",
      "  adversarial loss: 0.7685407996177673\n",
      "2900/10000:\n",
      "  discriminator loss: 1.2033207416534424\n",
      "  adversarial loss: 0.7864481806755066\n",
      "3000/10000:\n",
      "  discriminator loss: 0.6914066076278687\n",
      "  adversarial loss: 0.7499955892562866\n",
      "3100/10000:\n",
      "  discriminator loss: 0.744437575340271\n",
      "  adversarial loss: 0.7613940238952637\n",
      "3200/10000:\n",
      "  discriminator loss: 0.6675949692726135\n",
      "  adversarial loss: 0.7569082975387573\n",
      "3300/10000:\n",
      "  discriminator loss: 0.6896388530731201\n",
      "  adversarial loss: 0.7543584704399109\n",
      "3400/10000:\n",
      "  discriminator loss: 0.6796393394470215\n",
      "  adversarial loss: 0.9606559872627258\n",
      "3500/10000:\n",
      "  discriminator loss: 0.6944904923439026\n",
      "  adversarial loss: 0.6760428547859192\n",
      "3600/10000:\n",
      "  discriminator loss: 0.6813839673995972\n",
      "  adversarial loss: 0.7103310823440552\n",
      "3700/10000:\n",
      "  discriminator loss: 0.70240318775177\n",
      "  adversarial loss: 0.7440236210823059\n",
      "3800/10000:\n",
      "  discriminator loss: 0.7103120684623718\n",
      "  adversarial loss: 0.7435311079025269\n",
      "3900/10000:\n",
      "  discriminator loss: 0.6885356903076172\n",
      "  adversarial loss: 0.7848196029663086\n",
      "4000/10000:\n",
      "  discriminator loss: 0.7281810641288757\n",
      "  adversarial loss: 0.790561318397522\n",
      "4100/10000:\n",
      "  discriminator loss: 0.6972517967224121\n",
      "  adversarial loss: 0.7695972323417664\n",
      "4200/10000:\n",
      "  discriminator loss: 0.6901038289070129\n",
      "  adversarial loss: 0.8101831674575806\n",
      "4300/10000:\n",
      "  discriminator loss: 0.6917873620986938\n",
      "  adversarial loss: 0.7293760180473328\n",
      "4400/10000:\n",
      "  discriminator loss: 0.697036862373352\n",
      "  adversarial loss: 0.7401779890060425\n",
      "4500/10000:\n",
      "  discriminator loss: 0.7501518130302429\n",
      "  adversarial loss: 0.6583975553512573\n",
      "4600/10000:\n",
      "  discriminator loss: 0.6961926221847534\n",
      "  adversarial loss: 0.7649680376052856\n",
      "4700/10000:\n",
      "  discriminator loss: 0.7226666212081909\n",
      "  adversarial loss: 1.0327117443084717\n",
      "4800/10000:\n",
      "  discriminator loss: 0.6947498321533203\n",
      "  adversarial loss: 0.7762072682380676\n",
      "4900/10000:\n",
      "  discriminator loss: 0.6999309062957764\n",
      "  adversarial loss: 0.6536810994148254\n",
      "5000/10000:\n",
      "  discriminator loss: 0.7030207514762878\n",
      "  adversarial loss: 0.7195461392402649\n",
      "5100/10000:\n",
      "  discriminator loss: 0.6803845167160034\n",
      "  adversarial loss: 0.7192370891571045\n",
      "5200/10000:\n",
      "  discriminator loss: 0.7061536908149719\n",
      "  adversarial loss: 0.7804620862007141\n",
      "5300/10000:\n",
      "  discriminator loss: 0.7013551592826843\n",
      "  adversarial loss: 0.8248424530029297\n",
      "5400/10000:\n",
      "  discriminator loss: 0.6864451169967651\n",
      "  adversarial loss: 0.7100130915641785\n",
      "5500/10000:\n",
      "  discriminator loss: 0.6728359460830688\n",
      "  adversarial loss: 0.6465240716934204\n",
      "5600/10000:\n",
      "  discriminator loss: 0.6961740255355835\n",
      "  adversarial loss: 0.7617658376693726\n",
      "5700/10000:\n",
      "  discriminator loss: 0.7026236653327942\n",
      "  adversarial loss: 0.7024503350257874\n",
      "5800/10000:\n",
      "  discriminator loss: 0.6864004731178284\n",
      "  adversarial loss: 0.7310558557510376\n",
      "5900/10000:\n",
      "  discriminator loss: 0.7056053876876831\n",
      "  adversarial loss: 0.7479133605957031\n",
      "6000/10000:\n",
      "  discriminator loss: 0.67365562915802\n",
      "  adversarial loss: 1.428224802017212\n",
      "6100/10000:\n",
      "  discriminator loss: 0.681877613067627\n",
      "  adversarial loss: 0.7494741082191467\n",
      "6200/10000:\n",
      "  discriminator loss: 0.7091386318206787\n",
      "  adversarial loss: 0.734407901763916\n",
      "6300/10000:\n",
      "  discriminator loss: 0.6930705904960632\n",
      "  adversarial loss: 0.6735950708389282\n",
      "6400/10000:\n",
      "  discriminator loss: 0.7018027305603027\n",
      "  adversarial loss: 0.7361966967582703\n",
      "6500/10000:\n",
      "  discriminator loss: 0.6933544278144836\n",
      "  adversarial loss: 0.7460535168647766\n",
      "6600/10000:\n",
      "  discriminator loss: 0.6890779137611389\n",
      "  adversarial loss: 0.7181788682937622\n",
      "6700/10000:\n",
      "  discriminator loss: 0.7031959295272827\n",
      "  adversarial loss: 0.724946141242981\n",
      "6800/10000:\n",
      "  discriminator loss: 0.6831346154212952\n",
      "  adversarial loss: 0.7970567345619202\n",
      "6900/10000:\n",
      "  discriminator loss: 0.7104140520095825\n",
      "  adversarial loss: 0.7498458623886108\n",
      "7000/10000:\n",
      "  discriminator loss: 0.8063806295394897\n",
      "  adversarial loss: 0.8793155550956726\n",
      "7100/10000:\n",
      "  discriminator loss: 0.6869431138038635\n",
      "  adversarial loss: 0.7197058200836182\n",
      "7200/10000:\n",
      "  discriminator loss: 0.6983820796012878\n",
      "  adversarial loss: 0.7242581248283386\n",
      "7300/10000:\n",
      "  discriminator loss: 0.6653778553009033\n",
      "  adversarial loss: 0.7564824223518372\n",
      "7400/10000:\n",
      "  discriminator loss: 0.721049427986145\n",
      "  adversarial loss: 0.7928932905197144\n",
      "7500/10000:\n",
      "  discriminator loss: 0.6841427683830261\n",
      "  adversarial loss: 0.7620680928230286\n",
      "7600/10000:\n",
      "  discriminator loss: 0.6930902004241943\n",
      "  adversarial loss: 0.8314964175224304\n",
      "7700/10000:\n",
      "  discriminator loss: 0.7052544355392456\n",
      "  adversarial loss: 0.8399932980537415\n",
      "7800/10000:\n",
      "  discriminator loss: 0.6592156291007996\n",
      "  adversarial loss: 0.9349954724311829\n",
      "7900/10000:\n",
      "  discriminator loss: 0.7540985941886902\n",
      "  adversarial loss: 1.1084165573120117\n",
      "8000/10000:\n",
      "  discriminator loss: 0.6863516569137573\n",
      "  adversarial loss: 0.8201835751533508\n",
      "8100/10000:\n",
      "  discriminator loss: 0.7085052728652954\n",
      "  adversarial loss: 0.8655187487602234\n",
      "8200/10000:\n",
      "  discriminator loss: 0.6960834264755249\n",
      "  adversarial loss: 0.7939759492874146\n",
      "8300/10000:\n",
      "  discriminator loss: 0.6691521406173706\n",
      "  adversarial loss: 0.7704718112945557\n",
      "8400/10000:\n",
      "  discriminator loss: 0.7959930896759033\n",
      "  adversarial loss: 0.5588536262512207\n",
      "8500/10000:\n",
      "  discriminator loss: 0.6737521886825562\n",
      "  adversarial loss: 0.7910646200180054\n",
      "8600/10000:\n",
      "  discriminator loss: 0.653506875038147\n",
      "  adversarial loss: 0.8999041318893433\n",
      "8700/10000:\n",
      "  discriminator loss: 0.6784297227859497\n",
      "  adversarial loss: 0.7886731028556824\n",
      "8800/10000:\n",
      "  discriminator loss: 0.6592487096786499\n",
      "  adversarial loss: 0.7805606126785278\n",
      "8900/10000:\n",
      "  discriminator loss: 0.6733777523040771\n",
      "  adversarial loss: 0.7007075548171997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/10000:\n",
      "  discriminator loss: 0.6924470067024231\n",
      "  adversarial loss: 0.8190523982048035\n",
      "9100/10000:\n",
      "  discriminator loss: 0.6639738082885742\n",
      "  adversarial loss: 0.7115256190299988\n",
      "9200/10000:\n",
      "  discriminator loss: 0.7090044617652893\n",
      "  adversarial loss: 0.7607990503311157\n",
      "9300/10000:\n",
      "  discriminator loss: 0.6565305590629578\n",
      "  adversarial loss: 0.8645642995834351\n",
      "9400/10000:\n",
      "  discriminator loss: 0.7099415063858032\n",
      "  adversarial loss: 1.2284138202667236\n",
      "9500/10000:\n",
      "  discriminator loss: 0.6501067876815796\n",
      "  adversarial loss: 0.8638603091239929\n",
      "9600/10000:\n",
      "  discriminator loss: 0.6775126457214355\n",
      "  adversarial loss: 0.8674817085266113\n",
      "9700/10000:\n",
      "  discriminator loss: 0.6897228956222534\n",
      "  adversarial loss: 0.7588996887207031\n",
      "9800/10000:\n",
      "  discriminator loss: 0.7194375991821289\n",
      "  adversarial loss: 0.8644815683364868\n",
      "9900/10000:\n",
      "  discriminator loss: 0.6624621748924255\n",
      "  adversarial loss: 0.7602604031562805\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) +\n",
    "    (height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'DCGAN_example'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,\n",
    "                                            latent_dim))\n",
    "\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,\n",
    "                                            latent_dim))\n",
    "\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors,\n",
    "                                misleading_targets)\n",
    "\n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "      start = 0\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "\n",
    "        print(f'{step}/{iterations}:')\n",
    "        print(f'  discriminator loss: {d_loss}')\n",
    "        print(f'  adversarial loss: {a_loss}')\n",
    "\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,\n",
    "                      'generated_frog' + str(step) + '.png'))\n",
    "\n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,\n",
    "                      'real_frog' + str(step) + '.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
